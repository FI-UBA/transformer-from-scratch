{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import get_config, latest_weights_file_path\n",
    "from train import get_model, get_ds, run_validation\n",
    "from translate import translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\u001b[31;1m\n",
      "Filtering long sentences from the dataset...\u001b[0m\n",
      "Max source sequence length: 129 tokens.\n",
      "Max target sequence length: 120 tokens.\n",
      "\n",
      "Dataset size:    1320\n",
      "  Train size:    1188\n",
      "   Test size:     132\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "config = get_config()\n",
    "\n",
    "# Get the data loaders\n",
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "# Get the model and move it to the device\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "# Load the pretrained weights\n",
    "model_filename = latest_weights_file_path(config)\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Y teníamos un maestro que era un gran maestro, un viejo cangrejo. --Nunca fui a sus clases --dijo la Falsa Tortuga lloriqueando--, dicen que enseñaba patín y riego.\n",
      "    TARGET: Ele era um velho caranguejo, se era.\" \"Eu nunca fui a ele\", disse a Tartaruga Falsa com um suspiro: \"ele ensinava Risada e Tristeza, costumavam dizer\".\n",
      " PREDICTED: \" era um suspiro : ele ensinava Risada e Tristeza , se parece ser punida por isso .\"\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Dijeron que fuiste a verla y que a él le hablaste de mí: ella aprobó mi carácter y yo a nadar no aprendí.\n",
      "    TARGET: Eles me contaram que você tem sido para ela, e me mencionaram para ele: Ela me deu um bom sinal, mas disse que eu não podia nadar.\n",
      " PREDICTED: \" O que você tem sido para ela , e me mencionaram para ele : Ela me deu um bom sinal , mas disse que eu não faz .\"\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: --¡Valiente idiotez! --exclamó Alicia alzando la voz--.\n",
      "    TARGET: \"Idéia sem lógica!\" disse Alice em voz alta.\n",
      " PREDICTED: \" Idéia sem lógica !\" disse Alice em voz alta .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Edwindo Y Morcaro, duques de Mercia y Northumbría...»\n",
      "    TARGET: Edwin e Morcar, os condes de Mércia e Nortúmbria...\"\n",
      " PREDICTED: \" Venha , vamos tentar a primeira parte !\" disse a Tartaruga Falsa para o Grifo .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Había estado observando a Alicia con mucha curiosidad, y estas eran sus primeras palabras. –\n",
      "    TARGET: Ele estava olhando para Alice por algum tempo com grande curiosidade, e este foi sua primeira fala.\n",
      " PREDICTED: \" Alice respondeu olhando para Alice com cautela , e este foi sua primeira fala .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: ¡Chitón! --suplicó el Conejo con una vocecilla aterrada--.\n",
      "    TARGET: \"Oh silêncio!\" sussurrou o coelho num tom assustado.\n",
      " PREDICTED: \" Oh , você coelho num tom sussurrou o coelho num tom sussurrou .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: --Llámalo como quieras --dijo el Gato--.\n",
      "    TARGET: \"Chame do que você quiser\", disse o Gato.\n",
      " PREDICTED: \" Chame do que você quiser \", disse o Gato .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Alicia pensó que esto no demostraba nada. Sin embargo, continuó con sus preguntas: --¿Y cómo sabes que tú estás loco?\n",
      "    TARGET: \"Alice não achou que isto provasse nada afinal; contudo, ela continuou: \"E como você sabe que você é louco?\"\n",
      " PREDICTED: \" achou que isto provasse nada provasse nada : ela continuou , ela continuou : \" E como você sabe que você é louco ?\"\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Alicia pensó que todo esto era muy absurdo, pero los demás parecían tomarlo tan en serio que no se atrevió a reír, y, como tampoco se le ocurría nada que decir, se limitó a hacer una reverencia, y a coger el dedal, con el aire más solemne que pudo.\n",
      "    TARGET: Alice achou a coisa toda muito absurda, mas todos pareciam tão sérios que ela não ousou rir; e, como ela não pode pensar em nada para dizer, simplesmente fez uma mesura e pegou o dedal, da forma mais solene que podia.\n",
      " PREDICTED: \" achou que podia muito bem arrumado com uma mesura e , o que podia ver , o dedal , coisa certa se muito absurda em nada para fazer uma mesura e pegou o dedal , assim prevenindo de matar muito bem de que podia .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: ¡Ah, ya me acuerdo! --exclamó Alicia, que no había prestado atención a este último comentario--. Es un vegetal.\n",
      "    TARGET: \"Oh, eu sei! exclamou Alice, que não tinha prestado atenção neste último comentário, \"É um vegetal.\n",
      " PREDICTED: \" Oh , eu sei vegetal exclamou Alice , que não tinha prestado atenção neste último comentário , \" É um vegetal .\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# num_examples = len(val_dataloader) if config['training']['num_val_samples'] == -1 else config['training']['num_val_samples']\n",
    "num_examples = 10\n",
    "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['model']['seq_len'], device,\n",
    "               lambda msg: print(msg), 0, None, num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "    SOURCE: Hola, Este es el capítulo 10.\n",
      " PREDICTED: \" Espero que você avança duas vezes , com raiva !  "
     ]
    }
   ],
   "source": [
    "t = translate(\"Hola, Este es el capítulo 10.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "        ID: 34\n",
      "    SOURCE: (Dina era la gata.)\n",
      "    TARGET: (Diná era sua gata).\n",
      " PREDICTED: \" Você gata ).  "
     ]
    }
   ],
   "source": [
    "t = translate(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
